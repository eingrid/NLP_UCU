{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv run vllm serve Qwen/Qwen3-VL-8B-Instruct-FP8 \\\n",
    "#   --limit-mm-per-prompt.video 0 \\\n",
    "#   --async-scheduling \\\n",
    "#   --gpu-memory-utilization 0.6 \\\n",
    "#   --max-num-seqs 128 \\\n",
    "#   --max-model-len 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from src.utils import evaluate_accuracy\n",
    "\n",
    "samples = []\n",
    "with open('ua_asr_hypotheses_500.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    samples.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d534866",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a Ukrainian language expert. Choose the most accurate transcription based on:\n",
    "- Grammatical correctness\n",
    "- Natural word combinations\n",
    "- Proper word boundaries (e.g., \"по європейськи\" not \"поєвропейськи\")\n",
    "\n",
    "Options:\n",
    "{options}\n",
    "\n",
    "Reply with only the selected transcription number.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fb9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    timeout=3600\n",
    ")\n",
    "\n",
    "def inference_model(prompt, options):\n",
    "    prompt = prompt.format(options=options)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen3-VL-8B-Instruct-FP8\",\n",
    "        messages=messages,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.70%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "selected_hypotheses = []\n",
    "for sample in tqdm(samples):\n",
    "    options = \"\"\n",
    "    for idx, hypothesis in enumerate(sample['hypotheses']):\n",
    "        options += f\"{idx + 1}. {hypothesis}\\n\"\n",
    "    \n",
    "    response = inference_model(prompt, options)\n",
    "    try:\n",
    "        selected_index = int(response.strip()) - 1\n",
    "    except ValueError:\n",
    "        selected_index = 0  # Default to first option if parsing fails\n",
    "\n",
    "    selected_hypotheses.append(sample['hypotheses'][selected_index])\n",
    "\n",
    "accuracy = evaluate_accuracy(selected_hypotheses, samples)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1 (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
